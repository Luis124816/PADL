# -*- coding: utf-8 -*-
"""compress_image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16i-Q8CEmZcWMz_kXlhWVKGlx2EeqEOsQ
"""

# include whatever other imports you need here
import os
import shutil
import pandas as pd
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.transforms.functional as TF

# Your network definition goes here
class AutoEncoder(nn.Module):
    def __init__(self, latent_dim=32):
        super().__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.ReLU(),
        )
        self.flatten = nn.Flatten()
        self.mlp_enc = nn.Linear(256 * 12 * 10, latent_dim)

        # Decoder
        self.mlp_dec = nn.Linear(latent_dim, 256 * 12 * 10)
        self.decoder = nn.Sequential(
            nn.Unflatten(1, (256, 12, 10)),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, 2, 1),
            nn.Sigmoid()
        )

    def encode(self, x):
        x = self.encoder(x)
        x = self.flatten(x)
        return self.mlp_enc(x)

    def decode(self, z):
        x = self.mlp_dec(z)
        return self.decoder(x)

    def forward(self, x):
        return self.decode(self.encode(x))



def encode(images):
   # Determine which device the input tensor is on
   device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
   print("Using device: ", device)
   encoder = AutoEncoder()
   encoder = encoder.to(device)
   # Load network weights
   # ---------------- Please import 'q6_weights.pkl' to local google colab session ----------------
   encoder.load_state_dict(torch.load('q6_weights.pkl',map_location=torch.device(device)))
   # Put model in evaluation mode
   encoder.eval()
   # Optional: do whatever preprocessing you do on the inputs
   # if not included as tranformations inside the model
   # If your output needs any post-processing, do it here
   encoder.eval()
   with torch.no_grad():
    latents = encoder.encode(images)
    return latents


def decode(latents):
   # Determine which device the input tensor is on
   device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
   print("Using device: ", device)
   decoder = AutoEncoder()
   decoder = decoder.to(device)
   # Load network weights
   # ---------------- Please import 'q6_weights.pkl' to local google colab session ----------------
   decoder.load_state_dict(torch.load('q6_weights.pkl',map_location=torch.device(device)))
   # Put model in evaluation mode
   decoder.eval()
   with torch.no_grad():
    images = decoder.decode(latents)
    return images

# Testing on sample image
'''
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
image = Image.open("/content/2079.jpg").convert("L")
image_tensor = transforms.ToTensor()(image).unsqueeze(0).to(device)

encode(image_tensor)
print(encode(image_tensor))

decode(encode(image_tensor))
print(decode(encode(image_tensor)))
'''